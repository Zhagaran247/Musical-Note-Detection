{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhagaran247/Musical-Note-Detection/blob/main/Musical_note_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQI4U7A1h34o",
        "outputId": "225f59cd-792a-49fc-df32-dc9894b57dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "PATH = '/content/drive/MyDrive/projects/audio'\n",
        "\n",
        "!pip install -U kaleido\n",
        "\n",
        "# Configuration\n",
        "FPS = 30\n",
        "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
        "\n",
        "# Note range to display\n",
        "FREQ_MIN = 10\n",
        "FREQ_MAX = 1000\n",
        "\n",
        "# Notes to display\n",
        "TOP_NOTES = 3\n",
        "\n",
        "# Names of the notes\n",
        "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
        "\n",
        "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
        "RESOLUTION = (1920, 1080)\n",
        "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DidI5p7sxuWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y_VM7IqNmBv8",
        "outputId": "f96d9039-168e-46e2-ef54-a09cbf41c57b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eOd8Tm-jIW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "4010746b-87c8-4cce-f4f9-9dfb4681d794"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ex_note.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-36ecf94c6df3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mAUDIO_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/ex_note.wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAUDIO_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# this is a two channel soundtrack, get the first track\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mFRAME_STEP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mFPS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# audio samples per video frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ex_note.wav'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.fftpack import fft\n",
        "from scipy.io import wavfile # get the api\n",
        "import os\n",
        "\n",
        "AUDIO_FILE = \"/content/ex_note.wav\"\n",
        "\n",
        "fs, data = wavfile.read(os.path.join(PATH,AUDIO_FILE)) # load the data\n",
        "audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
        "FRAME_STEP = (fs / FPS) # audio samples per video frame\n",
        "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
        "AUDIO_LENGTH = len(audio)/fs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqxOflIuM_eT"
      },
      "source": [
        "Several utility functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg2kx9olG3ib"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
        "  layout = go.Layout(\n",
        "      title=\"frequency spectrum\",\n",
        "      autosize=False,\n",
        "      width=dimensions[0],\n",
        "      height=dimensions[1],\n",
        "      xaxis_title=\"Frequency (note)\",\n",
        "      yaxis_title=\"Magnitude\",\n",
        "      font={'size' : 24}\n",
        "  )\n",
        "\n",
        "  fig = go.Figure(layout=layout,\n",
        "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
        "                  layout_yaxis_range=[0,1]\n",
        "                  )\n",
        "\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x = xf,\n",
        "      y = p))\n",
        "\n",
        "  for note in notes:\n",
        "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
        "            text=note[1],\n",
        "            font = {'size' : 48},\n",
        "            showarrow=False)\n",
        "  return fig\n",
        "\n",
        "def extract_sample(audio, frame_number):\n",
        "  end = frame_number * FRAME_OFFSET\n",
        "  begin = int(end - FFT_WINDOW_SIZE)\n",
        "\n",
        "  if end == 0:\n",
        "    # We have no audio yet, return all zeros (very beginning)\n",
        "    return np.zeros((np.abs(begin)),dtype=float)\n",
        "  elif begin<0:\n",
        "    # We have some audio, padd with zeros\n",
        "    return np.concatenate([np.zeros((np.abs(begin)),dtype=float),audio[0:end]])\n",
        "  else:\n",
        "    # Usually this happens, return the next sample\n",
        "    return audio[begin:end]\n",
        "\n",
        "def find_top_notes(fft,num):\n",
        "  if np.max(fft.real)<0.001:\n",
        "    return []\n",
        "\n",
        "  lst = [x for x in enumerate(fft.real)]\n",
        "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
        "\n",
        "  idx = 0\n",
        "  found = []\n",
        "  found_note = set()\n",
        "  while( (idx<len(lst)) and (len(found)<num) ):\n",
        "    f = xf[lst[idx][0]]\n",
        "    y = lst[idx][1]\n",
        "    n = freq_to_number(f)\n",
        "    n0 = int(round(n))\n",
        "    name = note_name(n0)\n",
        "\n",
        "    if name not in found_note:\n",
        "      found_note.add(name)\n",
        "      s = [f,note_name(n0),y]\n",
        "      found.append(s)\n",
        "    idx += 1\n",
        "\n",
        "  return found"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t98k4AMRHy-o"
      },
      "source": [
        "Run the FFT on individual samples of the audio and generate video frames of the frequency chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7OinuERiRak"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "!rm /content/*.png\n",
        "\n",
        "# See https://newt.phys.unsw.edu.au/jw/notes.html\n",
        "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
        "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
        "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
        "\n",
        "# Hanning window function\n",
        "window = 0.5 * (1 - np.cos(np.linspace(0, 2*np.pi, FFT_WINDOW_SIZE, False)))\n",
        "\n",
        "xf = np.fft.rfftfreq(FFT_WINDOW_SIZE, 1/fs)\n",
        "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
        "FRAME_OFFSET = int(len(audio)/FRAME_COUNT)\n",
        "\n",
        "# Pass 1, find out the maximum amplitude so we can scale.\n",
        "mx = 0\n",
        "for frame_number in range(FRAME_COUNT):\n",
        "  sample = extract_sample(audio, frame_number)\n",
        "\n",
        "  fft = np.fft.rfft(sample * window)\n",
        "  fft = np.abs(fft).real\n",
        "  mx = max(np.max(fft),mx)\n",
        "\n",
        "print(f\"Max amplitude: {mx}\")\n",
        "\n",
        "# Pass 2, produce the animation\n",
        "for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
        "  sample = extract_sample(audio, frame_number)\n",
        "\n",
        "  fft = np.fft.rfft(sample * window)\n",
        "  fft = np.abs(fft) / mx\n",
        "\n",
        "  s = find_top_notes(fft,TOP_NOTES)\n",
        "\n",
        "  fig = plot_fft(fft.real,xf,fs,s,RESOLUTION)\n",
        "  fig.write_image(f\"/content/frame{frame_number}.png\",scale=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vo01yEzHeSu"
      },
      "source": [
        "Use [ffmpeg](https://ffmpeg.org/) to combine the input audio WAV and the individual frame images into a MP4 video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzPw9WT-Lfmy"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i frame%d.png -i {AUDIO_FILE} -c:v libx264 -pix_fmt yuv420p movie.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBbcVFuhHZgP"
      },
      "source": [
        "Download the generated movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ohuRzpfLkYg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('movie.mp4')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}